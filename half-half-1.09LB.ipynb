{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half and Half\n",
    "This notebook is the Python implementation of this awesomely simple R code: https://www.kaggle.com/kailex/ac-dc by [kxx](https://www.kaggle.com/kailex)\n",
    "\n",
    "It demonstrates splitting the data in half and using each half to build a model which performs very well on the public LB with minimal feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# path_data = \"/kaggle/input/ashrae-energy-prediction/\"\n",
    "# path_train = path_data + \"train.csv\"\n",
    "# path_test = path_data + \"test.csv\"\n",
    "# path_building = path_data + \"building_metadata.csv\"\n",
    "# path_weather_train = path_data + \"weather_train.csv\"\n",
    "# path_weather_test = path_data + \"weather_test.csv\"\n",
    "\n",
    "myfavouritenumber = 0\n",
    "seed = myfavouritenumber\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading train data\n",
    "Reading train data along with building and weather metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "building = pd.read_csv('building_metadata.csv')\n",
    "le = LabelEncoder()\n",
    "building.primary_use = le.fit_transform(building.primary_use)\n",
    "\n",
    "weather_train = pd.read_csv('data/weather_train.csv')\n",
    "weather_test = pd.read_csv('data/weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 173.90 MB\n",
      "Decreased by 71.8%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 74.9%\n",
      "Memory usage of dataframe is 8.58 MB\n",
      "Memory usage after optimization is: 2.26 MB\n",
      "Decreased by 73.7%\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train, use_float16=True)\n",
    "building = reduce_mem_usage(building, use_float16=True)\n",
    "weather_train = reduce_mem_usage(weather_train, use_float16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "There are two files with features that need to be merged with the data. One is building metadata that has information on the buildings and the other is weather data that has information on the weather.   \n",
    "\n",
    "Note that the only features created are hour, weekday and is_holiday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, building_data, weather_data, test=False):\n",
    "    \"\"\"\n",
    "    Preparing final dataset with all features.\n",
    "    \"\"\"\n",
    "    X\n",
    "    X = X.merge(building_data, on=\"building_id\", how=\"left\")\n",
    "    X = X.merge(weather_data, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "    \n",
    "    X.sort_values(\"timestamp\")\n",
    "    X.reset_index(drop=True)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                \"2019-01-01\"]\n",
    "    \n",
    "    X.timestamp = pd.to_datetime(X.timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    X.square_feet = np.log1p(X.square_feet)\n",
    "    \n",
    "    X[\"hour\"] = X.timestamp.dt.hour\n",
    "    X[\"weekday\"] = X.timestamp.dt.weekday\n",
    "    X[\"is_holiday\"] = (X.timestamp.isin(holidays)).astype(int)\n",
    "    \n",
    "    drop_features = [\"timestamp\", \"wind_direction\", \"wind_speed\"]\n",
    "\n",
    "    X.drop(drop_features, axis=1, inplace=True)\n",
    "    if not test:\n",
    "        X.drop(index=X[(X.meter_reading <=0) & (X.meter == 0)].index, inplace=True)\n",
    "\n",
    "    if test:\n",
    "        row_ids = X.row_id\n",
    "        X.drop(\"row_id\", axis=1, inplace=True)\n",
    "        return X, row_ids\n",
    "    else:\n",
    "        y = np.log1p(X.meter_reading)\n",
    "        X.drop(\"meter_reading\", axis=1, inplace=True)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather_train = timestamp_align(weather_train)\n",
    "X_train, y_train = prepare_data(df_train, building, weather_train)\n",
    "\n",
    "del df_train, weather_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-fold LightGBM Model split half-and-half\n",
    "The data is split into two based on time. Each half is used as the training data for a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with first half and validating on second half:\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 0.834404\tvalid_1's rmse: 1.06249\n",
      "[400]\ttraining's rmse: 0.792995\tvalid_1's rmse: 1.04974\n",
      "[600]\ttraining's rmse: 0.773513\tvalid_1's rmse: 1.05095\n",
      "Early stopping, best iteration is:\n",
      "[432]\ttraining's rmse: 0.789222\tvalid_1's rmse: 1.04896\n",
      "Building model with second half and validating on first half:\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 0.847961\tvalid_1's rmse: 1.05908\n",
      "[400]\ttraining's rmse: 0.805171\tvalid_1's rmse: 1.04541\n",
      "[600]\ttraining's rmse: 0.785137\tvalid_1's rmse: 1.04214\n",
      "[800]\ttraining's rmse: 0.770398\tvalid_1's rmse: 1.04202\n",
      "Early stopping, best iteration is:\n",
      "[766]\ttraining's rmse: 0.77265\tvalid_1's rmse: 1.0418\n"
     ]
    }
   ],
   "source": [
    "X_half_1 = X_train[:int(X_train.shape[0] / 2)]\n",
    "X_half_2 = X_train[int(X_train.shape[0] / 2):]\n",
    "\n",
    "y_half_1 = y_train[:int(X_train.shape[0] / 2)]\n",
    "y_half_2 = y_train[int(X_train.shape[0] / 2):]\n",
    "\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\", \"hour\", \"weekday\"]\n",
    "\n",
    "d_half_1 = lgb.Dataset(X_half_1, label=y_half_1, categorical_feature=categorical_features, free_raw_data=False)\n",
    "d_half_2 = lgb.Dataset(X_half_2, label=y_half_2, categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "watchlist_1 = [d_half_1, d_half_2]\n",
    "watchlist_2 = [d_half_2, d_half_1]\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 40,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"Building model with first half and validating on second half:\")\n",
    "model_half_1 = lgb.train(params, train_set=d_half_1, num_boost_round=1000, valid_sets=watchlist_1, verbose_eval=200, early_stopping_rounds=200)\n",
    "\n",
    "print(\"Building model with second half and validating on first half:\")\n",
    "model_half_2 = lgb.train(params, train_set=d_half_2, num_boost_round=1000, valid_sets=watchlist_2, verbose_eval=200, early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_half_1, X_half_2, y_half_1, y_half_2, d_half_1, d_half_2, watchlist_1, watchlist_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data\n",
    "Preparing test data with same features as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  building_id  meter            timestamp\n",
       "0                0            0      0  2017-01-01 00:00:00\n",
       "1                1            1      0  2017-01-01 00:00:00\n",
       "2                2            2      0  2017-01-01 00:00:00\n",
       "3                3            3      0  2017-01-01 00:00:00\n",
       "4                4            4      0  2017-01-01 00:00:00\n",
       "...            ...          ...    ...                  ...\n",
       "41697595  41697595         1444      0  2018-05-09 07:00:00\n",
       "41697596  41697596         1445      0  2018-05-09 07:00:00\n",
       "41697597  41697597         1446      0  2018-05-09 07:00:00\n",
       "41697598  41697598         1447      0  2018-05-09 07:00:00\n",
       "41697599  41697599         1448      0  2018-05-09 07:00:00\n",
       "\n",
       "[41697600 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1272.51 MB\n",
      "Memory usage after optimization is: 358.65 MB\n",
      "Decreased by 71.8%\n",
      "Memory usage of dataframe is 6.11 MB\n",
      "Memory usage after optimization is: 6.11 MB\n",
      "Decreased by 0.0%\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "# weather_test = pd.read_csv(path_weather_test)\n",
    "\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "weather_test = reduce_mem_usage(weather_test)\n",
    "\n",
    "X_test, row_ids = prepare_data(df_test, building, weather_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_test, building, weather_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring test data\n",
    "Averaging predictions from the two half train data models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.expm1(model_half_1.predict(X_test, num_iteration=model_half_1.best_iteration)) / 2\n",
    "\n",
    "del model_half_1\n",
    "gc.collect()\n",
    "\n",
    "pred += np.expm1(model_half_2.predict(X_test, num_iteration=model_half_2.best_iteration)) / 2\n",
    "    \n",
    "del model_half_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Preparing final file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(pred, 0, a_max=None)})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
